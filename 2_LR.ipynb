{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from itertools import combinations #will told me about this\n",
    "import scipy.optimize as opt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import jaccard_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"gender\"] = preprocessing.LabelEncoder().fit([\"male\", \"female\", \"non-binary\"]).transform(df[\"gender\"])\n",
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"interests\"] = preprocessing.LabelEncoder().fit([\"Sports\", \"Travel\", \"Lifestlye\"]).transform(df[\"interests\"])\n",
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"location\"] = preprocessing.LabelEncoder().fit([\"United States\", \"United Kingdom\", \"Australia\"]).transform(df[\"location\"])\n",
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"demographics\"] = preprocessing.LabelEncoder().fit([\"Urban\", \"Sub_Urban\", \"Rural\"]).transform(df[\"demographics\"])\n",
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"profession\"] = preprocessing.LabelEncoder().fit([\"Student\", \"Software Engineer\", \"Marketer Manager\"]).transform(df[\"profession\"]) #these throw harmless warnings.\n",
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"indebt\"] = preprocessing.LabelEncoder().fit([\"False\", \"True\"]).transform(df[\"indebt\"])\n",
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"isHomeOwner\"] = preprocessing.LabelEncoder().fit([\"False\", \"True\"]).transform(df[\"isHomeOwner\"])\n",
      "/var/folders/np/wt2f_g3s42g_nygnmnbpcswr0000gn/T/ipykernel_32473/926083657.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Owns_Car\"] = preprocessing.LabelEncoder().fit([\"False\", \"True\"]).transform(df[\"Owns_Car\"])\n"
     ]
    }
   ],
   "source": [
    "#create and clean data (I just did this before, I don't need to explain each step again)\n",
    "d = pd.read_csv(\"dummy_data.csv\")\n",
    "df = d[[\"time_spent\", \"age\", \"gender\", \"interests\", \"location\", \"demographics\", \"profession\", \"income\", \"indebt\", \"isHomeOwner\", \"Owns_Car\"]]\n",
    "df[\"gender\"] = preprocessing.LabelEncoder().fit([\"male\", \"female\", \"non-binary\"]).transform(df[\"gender\"])\n",
    "df[\"interests\"] = preprocessing.LabelEncoder().fit([\"Sports\", \"Travel\", \"Lifestlye\"]).transform(df[\"interests\"])\n",
    "df[\"location\"] = preprocessing.LabelEncoder().fit([\"United States\", \"United Kingdom\", \"Australia\"]).transform(df[\"location\"])\n",
    "df[\"demographics\"] = preprocessing.LabelEncoder().fit([\"Urban\", \"Sub_Urban\", \"Rural\"]).transform(df[\"demographics\"])\n",
    "df[\"profession\"] = preprocessing.LabelEncoder().fit([\"Student\", \"Software Engineer\", \"Marketer Manager\"]).transform(df[\"profession\"]) #these throw harmless warnings.\n",
    "df[\"indebt\"] = preprocessing.LabelEncoder().fit([\"False\", \"True\"]).transform(df[\"indebt\"])\n",
    "df[\"isHomeOwner\"] = preprocessing.LabelEncoder().fit([\"False\", \"True\"]).transform(df[\"isHomeOwner\"])\n",
    "df[\"Owns_Car\"] = preprocessing.LabelEncoder().fit([\"False\", \"True\"]).transform(df[\"Owns_Car\"])\n",
    "X = df[[\"time_spent\", \"age\", \"gender\", \"interests\", \"location\", \"demographics\", \"profession\", \"income\", \"indebt\", \"isHomeOwner\", \"Owns_Car\"]].values.astype(float) \n",
    "features = [\"age\", \"gender\", \"interests\", \"demographics\", \"profession\", \"income\", \"indebt\", \"isHomeOwner\", \"Owns_Car\"]\n",
    "ind = df[features]\n",
    "deps = df[[\"time_spent\"]]\n",
    "ind = pd.DataFrame(preprocessing.StandardScaler().fit(ind).transform(ind))\n",
    "ind.columns = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore the above warnings. They are harmless and not simple to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>interests</th>\n",
       "      <th>demographics</th>\n",
       "      <th>profession</th>\n",
       "      <th>income</th>\n",
       "      <th>indebt</th>\n",
       "      <th>isHomeOwner</th>\n",
       "      <th>Owns_Car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.112882</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>1.244883</td>\n",
       "      <td>0.056541</td>\n",
       "      <td>1.609380</td>\n",
       "      <td>1.006018</td>\n",
       "      <td>-1.016130</td>\n",
       "      <td>-1.081294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371652</td>\n",
       "      <td>-1.229356</td>\n",
       "      <td>1.238658</td>\n",
       "      <td>1.244883</td>\n",
       "      <td>1.285703</td>\n",
       "      <td>-1.505106</td>\n",
       "      <td>1.006018</td>\n",
       "      <td>0.984126</td>\n",
       "      <td>0.924818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.666069</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>-1.172620</td>\n",
       "      <td>-0.594094</td>\n",
       "      <td>-0.994018</td>\n",
       "      <td>-1.016130</td>\n",
       "      <td>-1.081294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.409373</td>\n",
       "      <td>1.226900</td>\n",
       "      <td>1.238658</td>\n",
       "      <td>1.244883</td>\n",
       "      <td>1.285703</td>\n",
       "      <td>-0.850422</td>\n",
       "      <td>-0.994018</td>\n",
       "      <td>0.984126</td>\n",
       "      <td>-1.081294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.184929</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>-1.206866</td>\n",
       "      <td>1.244883</td>\n",
       "      <td>0.056541</td>\n",
       "      <td>-0.151776</td>\n",
       "      <td>-0.994018</td>\n",
       "      <td>0.984126</td>\n",
       "      <td>0.924818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    gender  interests  demographics  profession    income  \\\n",
       "0  1.112882 -0.001228   0.015896      1.244883    0.056541  1.609380   \n",
       "1  0.371652 -1.229356   1.238658      1.244883    1.285703 -1.505106   \n",
       "2 -0.666069 -0.001228   0.015896      0.018397   -1.172620 -0.594094   \n",
       "3  1.409373  1.226900   1.238658      1.244883    1.285703 -0.850422   \n",
       "4 -1.184929 -0.001228  -1.206866      1.244883    0.056541 -0.151776   \n",
       "\n",
       "     indebt  isHomeOwner  Owns_Car  \n",
       "0  1.006018    -1.016130 -1.081294  \n",
       "1  1.006018     0.984126  0.924818  \n",
       "2 -0.994018    -1.016130 -1.081294  \n",
       "3 -0.994018     0.984126 -1.081294  \n",
       "4 -0.994018     0.984126  0.924818  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect our independent variables\n",
    "ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      time_spent\n",
      "0             3\n",
      "1             2\n",
      "2             8\n",
      "3             5\n",
      "4             1\n",
      "..          ...\n",
      "995           8\n",
      "996           6\n",
      "997           5\n",
      "998           4\n",
      "999           8\n",
      "\n",
      "[1000 rows x 1 columns]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for logistic regression, we should make the dependent variable binary\n",
    "print(deps.head)\n",
    "new_deps = []\n",
    "for cat in deps.time_spent:\n",
    "    if int(cat) > 4: new_deps.append(1)\n",
    "    else: new_deps.append(0)\n",
    "new_deps = np.asarray(new_deps)\n",
    "new_deps[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all possible combinations of features\n",
    "feature_combs = []\n",
    "for length in range(1, len(features) + 1):\n",
    "    feature_combs.extend(list(combinations(features, length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    m = LogisticRegression(C=0.01, solver='liblinear').fit(train_i,train_d)\n",
    "    yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "    acc = metrics.accuracy_score(test_d, yhat) #gets accuracy score on test set\n",
    "    acc_list.append([acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc_list) #considering random would be 0.5 accuracy, is this more impressive? Let's try different solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.61]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    m = LogisticRegression(C=0.01, solver='newton-cholesky').fit(train_i,train_d)\n",
    "    yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "    acc = metrics.accuracy_score(test_d, yhat) #gets accuracy score on test set\n",
    "    acc_list.append([acc])\n",
    "max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.61]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    m = LogisticRegression(C=0.01, solver='lbfgs').fit(train_i,train_d)\n",
    "    yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "    acc = metrics.accuracy_score(test_d, yhat) #gets accuracy score on test set\n",
    "    acc_list.append([acc])\n",
    "max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.61]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    m = LogisticRegression(C=0.01, solver='sag').fit(train_i,train_d)\n",
    "    yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "    acc = metrics.accuracy_score(test_d, yhat) #gets accuracy score on test set\n",
    "    acc_list.append([acc])\n",
    "max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.61]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    m = LogisticRegression(C=0.01, solver='saga').fit(train_i,train_d)\n",
    "    yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "    acc = metrics.accuracy_score(test_d, yhat) #gets accuracy score on test set\n",
    "    acc_list.append([acc])\n",
    "max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liblinear seems to be pretty clearly the best one. Let's try different C values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    for c_val in [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.5, 1.0]:\n",
    "        m = LogisticRegression(C=c_val, solver='liblinear').fit(train_i,train_d)\n",
    "        yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "        acc = metrics.accuracy_score(test_d, yhat) #gets accuracy score on test set\n",
    "        acc_list.append([acc, c_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62, 0.01]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay. maybe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62, 0.017]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    for c_val in [0.006, 0.007, 0.008, 0.0085, 0.0090, 0.0095, 0.0096, 0.0097, 0.0098, 0.0099, 0.01, 0.0101, 0.0102, 0.0103, 0.0104, 0.0105, 0.0106, 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017]:\n",
    "        m = LogisticRegression(C=c_val, solver='liblinear').fit(train_i,train_d)\n",
    "        yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "        acc = metrics.accuracy_score(test_d, yhat) #gets accuracy score on test set\n",
    "        acc_list.append([acc, c_val])\n",
    "max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay, but I think that's just considering the c_val as important in the MAX. I should plot this. But first, let's try a better scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for comb in feature_combs:\n",
    "    comb_ind = ind[list(comb)]\n",
    "    train_d, test_d, train_i, test_i = train_test_split(new_deps, comb_ind, test_size=0.2, random_state=5) #split data\n",
    "    m = LogisticRegression(C=0.01, solver='liblinear').fit(train_i,train_d)\n",
    "    yhat = m.predict(test_i)  #generates predictions for model m on test set\n",
    "    acc = jaccard_score(test_d, yhat,pos_label=0) #gets jaccard score on test set\n",
    "    acc_list.append([acc])\n",
    "max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wow, that's bad. let's see the confusion matrix for the best model we have on all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix    ---- THIS IS CODE FROM THE LOGISTIC REGRESSION LAB. I DID NOT WRITE THIS\n",
    "# train_d, test_d, train_i, test_i = train_test_split(new_deps, ind, test_size=0.2, random_state=5) #split data\n",
    "# m = LogisticRegression(C=0.01, solver='liblinear').fit(train_i,train_d)\n",
    "# yhat = m.predict(test_i)\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# import itertools\n",
    "# def plot_confusion_matrix(cm, classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "\n",
    "# cnf_matrix = confusion_matrix(test_d, yhat, labels=[1,0])\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=['1','0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#that's not fantastic either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884879265364838"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check the probability using log_loss\n",
    "from sklearn.metrics import log_loss\n",
    "prob = m.predict_proba(test_i)\n",
    "log_loss(test_d, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is just below the non-informative value (0.693) within reasonable error--this model is also not very effective here. As a last resort, let's try making a SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
